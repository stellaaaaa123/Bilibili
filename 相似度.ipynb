{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['also', 'football', 'games', 'john', 'likes', 'mary', 'movies', 'to', 'too', 'watch']\n",
      "[[0 0 0 1 2 1 2 1 1 1]\n",
      " [1 1 1 1 1 0 0 1 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "\"John likes to watch movies, Mary likes movies too\",\n",
    "\"John also likes to watch football games\",\n",
    "]\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import jieba\n",
    "import numpy as np\n",
    "from scipy.linalg import norm\n",
    "model_file = r\"C:\\Users\\CANDY\\Desktop\\毕设\\草稿\\news_12g_baidubaike_20g_novel_90g_embedding_64.bin\"\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(model_file, binary=True)\n",
    "#调用了一个现成的基于百度百科训练的模型（但是只支持纯文本）\n",
    "def vector_similarity(s1, s2):\n",
    "    def sentence_vector(s):\n",
    "        words = jieba.lcut(s)\n",
    "        v = np.zeros(64)\n",
    "        for word in words:\n",
    "            v += model[word]\n",
    "        v /= len(words)\n",
    "        return v\n",
    " \n",
    "    v1, v2 = sentence_vector(s1), sentence_vector(s2)\n",
    "    return np.dot(v1, v2) / (norm(v1) * norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\CANDY\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.786 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1775401052355638"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = '生活日常'\n",
    "s2 = '食品饮料'\n",
    "vector_similarity(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24692325069819782"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = '生活搞笑'\n",
    "s2 = '美妆护理'\n",
    "vector_similarity(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34455890162607267"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = '生活日常'\n",
    "s2 = '美妆护理'\n",
    "vector_similarity(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11199472586549872"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = '生活搞笑'\n",
    "s2 = '食品饮料'\n",
    "vector_similarity(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26612935093729895"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = '生活出行'\n",
    "s2 = '美妆护理'\n",
    "vector_similarity(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17204053281157017"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = '生活三农'\n",
    "s2 = '医药保健'\n",
    "vector_similarity(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24692325069819782"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = '生活搞笑'\n",
    "s2 = '美妆护理'\n",
    "vector_similarity(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3877587921711751"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = '生活日常'\n",
    "s2 = '美妆护理'\n",
    "vector_similarity(s1, s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目前有五种计算图片相似度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1：均值哈希算法（Average hash algorithm）基于比较灰度图每个像素与平均值来实现的，最适用于缩略图，放大图搜索。\n",
    "\n",
    "优点：\n",
    "    1：算法简单计算速度快\n",
    "    2：图像放大，缩小，改变纵横比，或增加，减少亮度，对比度，颜色对hash影响不大\n",
    "\n",
    "缺点：\n",
    "    对图片内容敏感，如果内容改变，图片hash改变比较大\n",
    "    \n",
    "2：差值哈希算法（Different hash algorithm）\n",
    "相比aHash，dHash在效率几乎相同的情况下的效果要更好，它是基于渐变实现的\n",
    "\n",
    "3：感知哈希算法（perceptual hash algorithm）采用的是DCT（离散余弦变换）来降低频率的方法\n",
    "\n",
    "优点：\n",
    "    简单快速，准确度更大\n",
    "\n",
    "缺点：\n",
    "    图片内容稍微添加几个字或删除几个字影响比较大\n",
    "    \n",
    "均值哈希算法、差值哈希算法和感知哈希算法都是值越小，相似度越高，取值为0-64，即汉明距离中，64位的hash值有多少不同。 三直方图和单通道直方图的值为0-1，值越大，相似度越高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Hash值对比\n",
    "def cmpHash(hash1, hash2,shape=(10,10)):\n",
    "    n = 0\n",
    "    # hash长度不同则返回-1代表传参出错\n",
    "    if len(hash1)!=len(hash2):\n",
    "        return -1\n",
    "    # 遍历判断\n",
    "    for i in range(len(hash1)):\n",
    "        # 相等则n计数+1，n最终为相似度\n",
    "        if hash1[i] == hash2[i]:\n",
    "            n = n + 1\n",
    "    return n/(shape[0]*shape[1])\n",
    "# 感知哈希算法(pHash)\n",
    "def pHash(img,shape=(10,10)):\n",
    "    # 缩放32*32\n",
    "    img = cv2.resize(img, (32, 32))  # , interpolation=cv2.INTER_CUBIC\n",
    "\n",
    "    # 转换为灰度图\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # 将灰度图转为浮点型，再进行dct变换\n",
    "    dct = cv2.dct(np.float32(gray))\n",
    "    # opencv实现的掩码操作\n",
    "    dct_roi = dct[0:10, 0:10]\n",
    "\n",
    "    hash = []\n",
    "    avreage = np.mean(dct_roi)\n",
    "    for i in range(dct_roi.shape[0]):\n",
    "        for j in range(dct_roi.shape[1]):\n",
    "            if dct_roi[i, j] > avreage:\n",
    "                hash.append(1)\n",
    "            else:\n",
    "                hash.append(0)\n",
    "    return hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过得到RGB每个通道的直方图来计算相似度\n",
    "def classify_hist_with_split(image1, image2, size=(256, 256)):\n",
    "    # 将图像resize后，分离为RGB三个通道，再计算每个通道的相似值\n",
    "    image1 = cv2.resize(image1, size)\n",
    "    image2 = cv2.resize(image2, size)\n",
    "    sub_image1 = cv2.split(image1)\n",
    "    sub_image2 = cv2.split(image2)\n",
    "    sub_data = 0\n",
    "    for im1, im2 in zip(sub_image1, sub_image2):\n",
    "        sub_data += calculate(im1, im2)\n",
    "    sub_data = sub_data / 3\n",
    "    return sub_data\n",
    "\n",
    "\n",
    "# 计算单通道的直方图的相似值\n",
    "def calculate(image1, image2):\n",
    "    hist1 = cv2.calcHist([image1], [0], None, [256], [0.0, 255.0])\n",
    "    hist2 = cv2.calcHist([image2], [0], None, [256], [0.0, 255.0])\n",
    "    # 计算直方图的重合度\n",
    "    degree = 0\n",
    "    for i in range(len(hist1)):\n",
    "        if hist1[i] != hist2[i]:\n",
    "            degree = degree + (1 - abs(hist1[i] - hist2[i]) / max(hist1[i], hist2[i]))\n",
    "        else:\n",
    "            degree = degree + 1\n",
    "    degree = degree / len(hist1)\n",
    "    return degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算单通道的直方图的相似值\n",
    "def calculate(image1, image2):\n",
    "    hist1 = cv2.calcHist([image1], [0], None, [256], [0.0, 255.0])\n",
    "    hist2 = cv2.calcHist([image2], [0], None, [256], [0.0, 255.0])\n",
    "    # 计算直方图的重合度\n",
    "    degree = 0\n",
    "    for i in range(len(hist1)):\n",
    "        if hist1[i] != hist2[i]:\n",
    "            degree = degree + (1 - abs(hist1[i] - hist2[i]) / max(hist1[i], hist2[i]))\n",
    "        else:\n",
    "            degree = degree + 1\n",
    "    degree = degree / len(hist1)\n",
    "    return degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "感知哈希算法相似度： 0.54\n",
      "三直方图算法相似度： 0.7312866\n",
      "单通道的直方图算法相似度： 0.73664105\n"
     ]
    }
   ],
   "source": [
    "img1 = cv2.imread(r\"C:\\Users\\CANDY\\Desktop\\pppp\\12.jpg\")  \n",
    "img2 = cv2.imread(r\"C:\\Users\\CANDY\\Desktop\\pppp\\11.jpg\")\n",
    "hash1 = pHash(img1)\n",
    "hash2 = pHash(img2)\n",
    "n = cmpHash(hash1, hash2)\n",
    "print('感知哈希算法相似度：', n)\n",
    "\n",
    "n = classify_hist_with_split(img1, img2)\n",
    "print('三直方图算法相似度：', n[0])\n",
    "\n",
    "n = calculate(img1, img2)\n",
    "print('单通道的直方图算法相似度：', n[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
