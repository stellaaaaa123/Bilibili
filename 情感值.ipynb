{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import re\n",
    "import jieba\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import csv\n",
    "import pandas as pd\n",
    "stop_word = pd.read_csv(r\"C:\\Users\\CANDY\\代码\\停用词.txt\",quoting=csv.QUOTE_NONE,sep='\\t',encoding='utf-8',names=['w'])\n",
    "stoplist = list(stop_word.w)\n",
    "stoplist\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#生成stopword表，需要去除一些否定词和程度词汇\n",
    "stopwords = set()\n",
    "fr = open(r'C:\\Users\\CANDY\\代码\\停用词.txt','r',encoding='utf-8')\n",
    "for word in fr:\n",
    "    stopwords.add(word.strip())#Python strip() 方法用于移除字符串头尾指定的字符（默认为空格或换行符）或字符序列。\n",
    "#读取否定词文件\n",
    "not_word_file = open(r'C:\\Users\\CANDY\\代码\\否定词.txt','r+',encoding='utf-8')\n",
    "not_word_list = not_word_file.readlines()\n",
    "not_word_list = [w.strip() for w in not_word_list]\n",
    "#读取程度副词文件\n",
    "degree_file = open(r'C:\\Users\\CANDY\\代码\\程度副词.txt','r+',encoding='utf-8')\n",
    "degree_list = degree_file.readlines()\n",
    "degree_list = [item.split(',')[0] for item in degree_list]\n",
    "#生成新的停用词表\n",
    "with open('stopwords.txt','w',encoding='utf-8') as f:\n",
    "    for word in stopwords:\n",
    "        if(word not in not_word_list) and (word not in degree_list):\n",
    "            f.write(word+'\\n')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jieba分词后去除停用词\n",
    "def seg_word(sentence):\n",
    "    seg_list = jieba.cut(sentence)\n",
    "    seg_result = []\n",
    "    for i in seg_list:\n",
    "        seg_result.append(i)\n",
    "    stopwords = set()\n",
    "    with open('stopwords.txt','r',encoding='utf-8') as fr:\n",
    "        for i in fr:\n",
    "            stopwords.add(i.strip())\n",
    "    return list(filter(lambda x :x not in stopwords,seg_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TabError",
     "evalue": "inconsistent use of tabs and spaces in indentation (<ipython-input-3-44a7a9a8f941>, line 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-44a7a9a8f941>\"\u001b[1;36m, line \u001b[1;32m24\u001b[0m\n\u001b[1;33m    sen_word = dict()\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mTabError\u001b[0m\u001b[1;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"
     ]
    }
   ],
   "source": [
    "#找出文本中的情感词、否定词和程度副词\n",
    "def classify_words(word_list):\n",
    "    #读取情感词典文件\n",
    "    sen_file = open(r'C:\\Users\\CANDY\\代码\\BosonNLP_sentiment_score.txt','r+',encoding='utf-8')\n",
    "    #获取词典文件内容\n",
    "    sen_list = sen_file.readlines()\n",
    "    #创建情感字典\n",
    "    sen_dict = defaultdict()\n",
    "    #读取词典每一行的内容，将其转换成字典对象，key为情感词，value为其对应的权重\n",
    "    for i in sen_list:\n",
    "        if len(i.split(' '))==2:\n",
    "            sen_dict[i.split(' ')[0]] = i.split(' ')[1]\n",
    " \n",
    "    #读取否定词文件\n",
    "    not_word_file = open(r'C:\\Users\\CANDY\\代码\\否定词.txt','r+',encoding='utf-8')\n",
    "    not_word_list = not_word_file.readlines()\n",
    "    #读取程度副词文件\n",
    "    degree_file = open(r'C:\\Users\\CANDY\\代码\\程度副词.txt','r+',encoding='utf-8')\n",
    "    degree_list = degree_file.readlines()\n",
    "    degree_dict = defaultdict()\n",
    "    for i in degree_list:\n",
    "        degree_dict[i.split(',')[0]] = i.split(',')[1]\n",
    " \n",
    "\tsen_word = dict()\n",
    "\tnot_word = dict()\n",
    "\tdegree_word = dict()\n",
    "\t#分类\n",
    "\tfor i in range(len(word_list)):\n",
    "\t\tword = word_list[i]\n",
    "\t\tif word in sen_dict.keys() and word not in not_word_list and word not in degree_dict.keys():\n",
    "\t\t\t# 找出分词结果中在情感字典中的词\n",
    "\t\t\tsen_word[i] = sen_dict[word]\n",
    "\t\telif word in not_word_list and word not in degree_dict.keys():\n",
    "\t\t\t# 分词结果中在否定词列表中的词\n",
    "\t\t\tnot_word[i] = -1\n",
    "\t\telif word in degree_dict.keys():\n",
    "\t\t\t# 分词结果中在程度副词中的词\n",
    "\t\t\tdegree_word[i]  = degree_dict[word]\n",
    " \n",
    " \n",
    "\t#关闭打开的文件\n",
    "\tsen_file.close()\n",
    "\tnot_word_file.close()\n",
    "\tdegree_file.close()\n",
    "\t#返回分类结果\n",
    "\treturn sen_word,not_word,degree_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我今天很高兴也非常开心     2.61234173173\n",
      "天灰蒙蒙的，路上有只流浪狗，旁边是破旧不堪的老房子    -1.8760024465746\n",
      "愤怒、悲伤和埋怨解决不了问题     -3.369079988548\n",
      "要每天都开心快乐     6.79232134331\n",
      "我不喜欢这个世界，我只喜欢你     5.367487561038\n"
     ]
    }
   ],
   "source": [
    "#计算情感词的分数\n",
    "def score_sentiment(sen_word,not_word,degree_word,seg_result):\n",
    "    #权重初始化为1\n",
    "    W = 1\n",
    "    score = 0\n",
    "    #情感词下标初始化\n",
    "    sentiment_index = -1\n",
    "    #情感词的位置下标集合\n",
    "    sentiment_index_list = list(sen_word.keys())\n",
    "    #遍历分词结果\n",
    "    for i in range(0,len(seg_result)):\n",
    "        #如果是情感词\n",
    "        if i in sen_word.keys():\n",
    "            #权重*情感词得分\n",
    "            score += W*float(sen_word[i])\n",
    "            #情感词下标加一，获取下一个情感词的位置\n",
    "            sentiment_index += 1\n",
    "            if sentiment_index < len(sentiment_index_list)-1:\n",
    "                #判断当前的情感词与下一个情感词之间是否有程度副词或否定词\n",
    "                for j in range(sentiment_index_list[sentiment_index],sentiment_index_list[sentiment_index+1]):\n",
    "                    #更新权重，如果有否定词，权重取反\n",
    "                    if j in not_word.keys():\n",
    "                        W *= -1\n",
    "                    elif j in degree_word.keys():\n",
    "                        W *= float(degree_word[j])\n",
    "        #定位到下一个情感词\n",
    "        if sentiment_index < len(sentiment_index_list)-1:\n",
    "            i = sentiment_index_list[sentiment_index+1]\n",
    "    return score\n",
    " \n",
    "#计算得分\n",
    "def sentiment_score(sentence):\n",
    "    #1.对文档分词\n",
    "    seg_list = seg_word(sentence)\n",
    "    #2.将分词结果转换成字典，找出情感词、否定词和程度副词\n",
    "    sen_word,not_word,degree_word = classify_words(seg_list)\n",
    "    #3.计算得分\n",
    "    score = score_sentiment(sen_word,not_word,degree_word,seg_list)\n",
    "    return score\n",
    " \n",
    "print(\"我今天很高兴也非常开心    \",sentiment_score(\"我今天很高兴也非常开心\"))\n",
    "print('天灰蒙蒙的，路上有只流浪狗，旁边是破旧不堪的老房子   ',sentiment_score('天灰蒙蒙的，路上有只流浪狗，旁边是破旧不堪的老房子'))\n",
    "print('愤怒、悲伤和埋怨解决不了问题    ',sentiment_score('愤怒、悲伤和埋怨解决不了问题'))\n",
    "print('要每天都开心快乐    ',sentiment_score('要每天都开心快乐'))\n",
    "print('我不喜欢这个世界，我只喜欢你    ',sentiment_score('我不喜欢这个世界，我只喜欢你'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "up主真好 0.859935517196\n",
      "up主nice 1.82528469071\n",
      "感谢金主爸爸 2.955561249614\n",
      "什么玩意，快跑 -0.821220640765\n",
      "假的，骗人 -1.167456647372\n",
      "闪子，你变了 -0.0696560125525\n"
     ]
    }
   ],
   "source": [
    "print('up主真好',sentiment_score('up主真好'))\n",
    "print('up主nice',sentiment_score('up主nice'))\n",
    "print('感谢金主爸爸',sentiment_score('感谢金主爸爸'))\n",
    "print('什么玩意，快跑',sentiment_score('什么玩意，快跑'))\n",
    "print('假的，骗人',sentiment_score('假的，骗人'))\n",
    "print('闪子，你变了',sentiment_score('闪子，你变了'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
