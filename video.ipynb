{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd   #引入库\n",
    "wb=xlrd.open_workbook(r\"C:\\Users\\CANDY\\Desktop\\广告编码1-200.xlsx\")\n",
    "sheet_names=wb.sheet_names() \n",
    "sheet=wb.sheet_by_index(1)  \n",
    "bvs=sheet.col_values(7)\n",
    "titleyuanbens=sheet.col_values(2)\n",
    "begins=sheet.col_values(3)\n",
    "ends=sheet.col_values(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#titleyuanbens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titles=[]\n",
    "from bilibili_api import video\n",
    "for i in range(1,len(bvs)):\n",
    "    try:#print(i)\n",
    "        bvid=bvs[i]\n",
    "        video_info=video.get_video_info(bvid=bvid)\n",
    "        titleyuanben = video_info[\"title\"]\n",
    "        #print(video_info[\"title\"])\n",
    "        titles.append(titleyuanben)\n",
    "    except:\n",
    "        titles.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.DataFrame()\n",
    "df1['title']=titles\n",
    "df1.to_excel(r\"C:\\Users\\CANDY\\Desktop\\testtitle.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#清除储存文件中原有的截图\n",
    "def del_file(path):\n",
    "    for i in os.listdir(path):\n",
    "        # 如果存在文件夹进行递归\n",
    "        if os.path.isdir(os.path.join(path, i)):\n",
    "            del_file(os.path.join(path, i))\n",
    "        # 如果是文件进行删除\n",
    "        elif os.path.isfile:\n",
    "            os.remove(os.path.join(path, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#遍历所有截图计算平均HSI\n",
    "def avghsv(path):\n",
    "    #初始化\n",
    "    hs=[]\n",
    "    ss=[]\n",
    "    vs=[]\n",
    "    img_paths=[]\n",
    "    dir_paths=os.listdir(path)\n",
    "    #得到每个图像的路径\n",
    "    for dir_path in dir_paths:\n",
    "        img_path=os.path.join(path,dir_path)\n",
    "        img_paths.append(img_path)\n",
    "    for img in img_paths:\n",
    "        if img.endswith('.jpg'): \n",
    "            #该图片的h,s,v平均值\n",
    "            pict=cv2.imread(img)\n",
    "            hsv=cv2.cvtColor(pict,cv2.COLOR_BGR2HSV)#转化成hsv空间\n",
    "            h=hsv[:,:,0]\n",
    "            s=hsv[:,:,1]\n",
    "            v=hsv[:,:,2]#像素矩阵最后一维012对应hsv三个字母\n",
    "            h_mean=np.mean(h)\n",
    "            s_mean=np.mean(s)\n",
    "            v_mean=np.mean(v)\n",
    "            hs.append(h_mean)\n",
    "            ss.append(s_mean)\n",
    "            vs.append(v_mean)\n",
    "    #求这几个图片的平均hsv\n",
    "    hs_mean=np.mean(hs)\n",
    "    ss_mean=np.mean(ss)\n",
    "    vs_mean=np.mean(vs)\n",
    "    \n",
    "    return hs_mean,ss_mean,vs_mean    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读入视频路径\n",
    "inputdir=r\"D:\\CRTubeGet Downloaded\"\n",
    "#输出图片路径\n",
    "outputdir=r\"C:\\Users\\CANDY\\Desktop\\video_to_ppt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "def process_video(start,end,videodir,outputdir):\n",
    "    #清除储存文件中原有的截图\n",
    "    del_file(outputdir)\n",
    "    # 定义视频文件路径和保存图像文件路径\n",
    "    video_path =videodir\n",
    "    save_path =outputdir\n",
    "    \n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "     # 定义起始和结束时间，以及帧数间隔\n",
    "    if start==0:\n",
    "        start_time =start # 单位为秒\n",
    "    else:\n",
    "        start_time=start-2\n",
    "    end_time =end# 单位为秒\n",
    "\n",
    "    # 打开视频文件\n",
    "    cap = cv2.VideoCapture(video_path) \n",
    "    # 从指定的时间开始读取视频帧\n",
    "    cap.set(cv2.CAP_PROP_POS_MSEC, start_time *1000) \n",
    "    # 定义计数器变量\n",
    "    i = 0 \n",
    "    # 读取视频帧，并保存每个间隔的帧为图像文件\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # 判断当前时间是否在指定的时间段内\n",
    "            current_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "            if current_time >= start_time and i<=50:\n",
    "                print(current_time)\n",
    "                # 保存当前帧为图像文件\n",
    "                out_file_name = str(i) + \".jpg\"\n",
    "                out_file_path = os.path.join(save_path, out_file_name)\n",
    "                cv2.imwrite(out_file_path, frame)\n",
    "                i += 1\n",
    "                print(\"processed frame:\", i-1)\n",
    "            if current_time >= end_time:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    # 关闭视频文件\n",
    "    cap.release()\n",
    "    return i-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hash值对比\n",
    "def cmpHash(hash1, hash2,shape=(10,10)):\n",
    "    n = 0\n",
    "    # hash长度不同则返回-1代表传参出错\n",
    "    if len(hash1)!=len(hash2):\n",
    "        return -1\n",
    "    # 遍历判断\n",
    "    for i in range(len(hash1)):\n",
    "        # 相等则n计数+1，n最终为相似度\n",
    "        if hash1[i] == hash2[i]:\n",
    "            n = n + 1\n",
    "    return n/(shape[0]*shape[1])\n",
    "# 感知哈希算法(pHash)\n",
    "def pHash(img,shape=(10,10)):\n",
    "    # 缩放32*32\n",
    "    img = cv2.resize(img, (32, 32))  # , interpolation=cv2.INTER_CUBIC\n",
    "\n",
    "    # 转换为灰度图\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # 将灰度图转为浮点型，再进行dct变换\n",
    "    dct = cv2.dct(np.float32(gray))\n",
    "    # opencv实现的掩码操作\n",
    "    dct_roi = dct[0:10, 0:10]\n",
    "\n",
    "    hash = []\n",
    "    avreage = np.mean(dct_roi)\n",
    "    for i in range(dct_roi.shape[0]):\n",
    "        for j in range(dct_roi.shape[1]):\n",
    "            if dct_roi[i, j] > avreage:\n",
    "                hash.append(1)\n",
    "            else:\n",
    "                hash.append(0)\n",
    "    return hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jieba\n",
    "#读取停用词\n",
    "\n",
    "def stopwordslist(filepath):\n",
    "    stopwords = [line.strip() for line in open(filepath, 'r+',encoding='utf-8').readlines()]\n",
    "    return stopwords\n",
    "\n",
    "# 加载停用词\n",
    "stopwords = stopwordslist(r'C:\\Users\\CANDY\\代码\\停用词.txt')\n",
    "\n",
    "def cosine_similarity(sentence1: str, sentence2: str) -> float:\n",
    "    \"\"\"\n",
    "    :param sentence1: s\n",
    "    :param sentence2:\n",
    "    :return: 两句文本的相识度\n",
    "    \"\"\"\n",
    "    seg1 = [word for word in jieba.cut(sentence1) if word not in stopwords]\n",
    "    seg2 = [word for word in jieba.cut(sentence2) if word not in stopwords]\n",
    "    word_list = list(set([word for word in seg1 + seg2]))#建立词库\n",
    "    word_count_vec_1 = []\n",
    "    word_count_vec_2 = []\n",
    "    for word in word_list:\n",
    "        word_count_vec_1.append(seg1.count(word))#文本1统计在词典里出现词的次数\n",
    "        word_count_vec_2.append(seg2.count(word))#文本2统计在词典里出现词的次数\n",
    "\n",
    "    vec_1 = np.array(word_count_vec_1)\n",
    "    vec_2 = np.array(word_count_vec_2)\n",
    "    #余弦公式\n",
    "\n",
    "    num = vec_1.dot(vec_2.T)\n",
    "    denom = np.linalg.norm(vec_1) * np.linalg.norm(vec_2)\n",
    "    cos = num / denom\n",
    "    sim = 0.5 + 0.5 * cos\n",
    "\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#修改路径\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "  \n",
    "\"\"\"对指定目录下的所有文件进行有选择的修改名称\"\"\"\n",
    "def ReFileName(dirPath,pattern):\n",
    "    \"\"\"\n",
    "    :param dirPath: 文件夹路径\n",
    "    :param pattern: 正则匹配模式\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 对目录下的文件进行遍历\n",
    "    #print(os.listdir(dirPath))\n",
    "    for file in os.listdir(dirPath):\n",
    "        #print(file)\n",
    "        # 判断是否是文件\n",
    "        if os.path.isfile(os.path.join(dirPath, file)) == True:\n",
    "            # 用正则匹配，去掉不需要的词\n",
    "            newName = re.sub(pattern, \"\", file)\n",
    "            print('newName',newName)\n",
    "            # 设置新文件名\n",
    "            newFilename = file.replace(file, newName)\n",
    "            print('newFilename',newFilename)\n",
    "            # 重命名\n",
    "            try:\n",
    "                os.rename(os.path.join(dirPath, file), os.path.join(dirPath, newFilename))\n",
    "            except:\n",
    "                pass\n",
    "    print(\"文件名已统一修改成功\")  \n",
    "   \n",
    "if __name__ == '__main__':\n",
    "    timeStart = time.time()\n",
    "    Path=r'D:\\CRTubeGet Downloaded'\n",
    "    \n",
    "#   pattern = re.compile(r'\\[{1}(.+)]\\.')\n",
    "    pattern = re.compile(r'-{1}(.+)zh')\n",
    "    ReFileName(Path,pattern)\n",
    "    timeEnd = time.time()\n",
    "    print(\"程序走了%d秒\"%(timeEnd-timeStart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re,openpyxl\n",
    "def docsimilarity(path,begin_time,end_time):\n",
    "    print(begin_time,end_time)\n",
    "    path=path\n",
    "    begintime=begin_time\n",
    "    endtime=end_time\n",
    "    new = []\n",
    "    zimubegins=[]\n",
    "    try:\n",
    "        \n",
    "        with open(path, encoding=\"utf-8-sig\") as f:\n",
    "            for sub in f.readlines():\n",
    "                if sub[:3]== '00:':\n",
    "                    begin_min= int(sub.split(':')[1])\n",
    "                    begin_sec= int(sub.split('-')[0].split(',')[0].split(':')[2])\n",
    "                    begin=begin_min*60+begin_sec\n",
    "                    zimubegins.append(begin)\n",
    "                #print(sub[0],sub[-1])\n",
    "                #if sub[0] not in list('\\n0123456789') and sub[-2] not in list('0123456789'):\n",
    "                if sub[0] not in list('\\n0123456789') and sub[-1] not in list('0123456789'):\n",
    "                    new.append(sub)\n",
    "        news = [ele.strip() for ele in new]\n",
    "        #print(news)\n",
    "        zimu=pd.DataFrame()\n",
    "        n=len(news)\n",
    "        zimubegins=zimubegins[:n]\n",
    "        zimu['begin']=zimubegins\n",
    "        zimu['new']=news\n",
    "        \n",
    "        ad=''\n",
    "        noad=''\n",
    "\n",
    "        for i in range(len(zimu)):\n",
    "            if begintime<=zimu.begin[i]<=endtime:\n",
    "                docsimilarity=1\n",
    "                ad=ad+','+zimu.new[i]\n",
    "            else:\n",
    "                noad=noad+','+zimu.new[i]\n",
    "        #print('ad',ad)\n",
    "        #print('noad',noad)\n",
    "        if len(noad)==0 and len(ad)!=0:\n",
    "            docsimilarity=1\n",
    "        elif len(ad)==0 and len(noad)!=0:\n",
    "            docsimilarity=0\n",
    "        else:\n",
    "            docsimilarity=cosine_similarity(ad,noad)  \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return docsimilarity    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list=os.listdir(inputdir)\n",
    "error=[]\n",
    "video=pd.DataFrame()\n",
    "#文件夹下有多少视频\n",
    "for j in range(92,93):\n",
    "    print('###')\n",
    "    titleyuanben=titleyuanbens[j]\n",
    "    start_time=int(begins[j])\n",
    "    end_time=int(ends[j])\n",
    "    print(titleyuanben)\n",
    "    title=titleyuanben\n",
    "    h=0\n",
    "    v=0\n",
    "    s=0\n",
    "    similarity=0\n",
    "    for i in range(len(file_list)):\n",
    "        inputdir_title=file_list[i].replace('.mp4','')\n",
    "        #title=inputdir_title.replace('.mp4','')\n",
    "        if inputdir_title==titleyuanben:\n",
    "            try:\n",
    "                print(\"Step 1:对视频截帧\")\n",
    "                videodir=os.path.join(inputdir,inputdir_title)+'.mp4'\n",
    "                print(videodir)\n",
    "                n=process_video(start_time,end_time,videodir,outputdir) \n",
    "                print(n)\n",
    "\n",
    "                print(\"Step 2:\")\n",
    "                print(\"计算图片相似度\")\n",
    "                if end_time==0:\n",
    "                    similarity=1.0\n",
    "                else:\n",
    "                    img1 = cv2.imread(r\"C:\\Users\\CANDY\\Desktop\\video_to_ppt\\0.jpg\")  \n",
    "                    img2 = cv2.imread(r\"C:\\Users\\CANDY\\Desktop\\video_to_ppt\\%d.jpg\"%(n))\n",
    "                    hash1 = pHash(img1)\n",
    "                    hash2 = pHash(img2)\n",
    "                    similarity=cmpHash(hash1, hash2)\n",
    "                print(similarity)\n",
    "                print(\"Step 3:\")\n",
    "                print(\"计算广告平均HSV\")\n",
    "                h,s,v=avghsv(outputdir)\n",
    "                print('h平均值为%s,\\ns平均值为%s,\\nv平均值为%s'%(h,s,v))\n",
    "\n",
    "                #item={'title':title,'h':h,'s':s,'v':v,'similarity':similarity}\n",
    "                #video=video.append(item,ignore_index=True)\n",
    "            except:\n",
    "                inputdir_title=file_list[i]\n",
    "                error.append(inputdir_title)\n",
    "    item={'title':title,'h':h,'s':s,'v':v,'picsimilarity':similarity}\n",
    "    video=video.append(item,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#文字相似度\n",
    "file_list=os.listdir(inputdir)\n",
    "video1=pd.DataFrame()\n",
    "#文件夹下有多少视频\n",
    "for j in range(92,93):\n",
    "    print('###')\n",
    "    titleyuanben=titleyuanbens[j]\n",
    "    start_time=int(begins[j])\n",
    "    end_time=int(ends[j])\n",
    "    print(titleyuanben)\n",
    "    title=titleyuanben\n",
    "    similarity=111\n",
    "    for i in range(len(file_list)):\n",
    "        inputdir_title=file_list[i].replace('.srt','')\n",
    "        \n",
    "        #title=inputdir_title.replace('.mp4','')\n",
    "        if inputdir_title==titleyuanben:\n",
    "            if end_time==0:\n",
    "                similarity=0\n",
    "            else:\n",
    "                print('计算文本相似度')    \n",
    "                srtdir=os.path.join(inputdir,inputdir_title)+'.srt'\n",
    "                print(srtdir)\n",
    "                similarity=docsimilarity(srtdir,begins[j],ends[j])\n",
    "                print(similarity)\n",
    "    item={'title':titleyuanben,'docsimilarity':similarity}\n",
    "    video1=video1.append(item,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.to_csv(r'C:\\Users\\CANDY\\Desktop\\video.csv',encoding=\"utf_8_sig\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
